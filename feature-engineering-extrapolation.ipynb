{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EY Data Science Challenge 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering - Extrapolation of Destination\n",
    "\n",
    "The idea behind this script is to extrapolate the end (x,y) coordinates for each hash group using the sequence of trajectories provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    \"vmax\" : np.float64,\n",
    "    \"vmin\" : np.float64,\n",
    "    \"vmean\" : np.float64,\n",
    "    \"x_entry\" : np.float64,\n",
    "    \"y_entry\" : np.float64,\n",
    "    \"x_exit\" : np.float64,\n",
    "    \"y_exit\" : np.float64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the training data\n",
    "train = pd.read_csv(\"data/data_train.csv\", dtype=dtype, index_col=0)\n",
    "train['time_entry'] = pd.to_datetime(train['time_entry'])\n",
    "train['time_exit'] = pd.to_datetime(train['time_exit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_seconds_from_midnight(timestamp):\n",
    "    \"\"\"\n",
    "    Converts timestamp into an integer (number of seconds from midnight).\n",
    "    \"\"\"\n",
    "    return timestamp.hour * 3600 + timestamp.minute * 60 + timestamp.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"time_entry\"] = train[\"time_entry\"].apply(compute_seconds_from_midnight)\n",
    "train[\"time_exit\"] = train[\"time_exit\"].apply(compute_seconds_from_midnight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing - flattening the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEATURES = 6\n",
    "N_REQUIRED_TRAJECTORIES = 6 # inclusive of the final trajectory\n",
    "\n",
    "def flatten_hash_group(group, is_train=True):\n",
    "    \n",
    "    # construct a new series to store the flattened hash instance\n",
    "    to_flatten = pd.Series(group[\"hash\"].unique())\n",
    "    \n",
    "    # pad the flattened array with zero-values\n",
    "    n_trajectories_to_pad = N_REQUIRED_TRAJECTORIES - len(group)\n",
    "    if n_trajectories_to_pad > 0:\n",
    "        padding = pd.Series([0] * n_trajectories_to_pad * N_FEATURES)\n",
    "        to_flatten = to_flatten.append(padding, ignore_index=True)\n",
    "    \n",
    "    # iterate through the last N_REQUIRED_TRAJECTORIES\n",
    "    for i in range(max(0, len(group) - N_REQUIRED_TRAJECTORIES), len(group)):\n",
    "        to_append = pd.Series(group.iloc[i][[\"x_entry\", \"y_entry\", \"time_entry\", \"x_exit\", \"y_exit\", \"time_exit\"]].values)\n",
    "        to_flatten = to_flatten.append(to_append, ignore_index=True)\n",
    "\n",
    "    return to_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df, outfile=\"data/train_fe_flat.csv\", n_iters_to_write=100, is_train=True):\n",
    "    \n",
    "    # overwrite the existing data file\n",
    "    with open(outfile, \"w\") as f:\n",
    "        pass\n",
    "    \n",
    "    # chunk through the hash groups, write to outfile\n",
    "    counter = 0\n",
    "    data = pd.DataFrame()\n",
    "    for _, hash_group in df.groupby(\"hash\"):\n",
    "        feature_vector = flatten_hash_group(hash_group, is_train)\n",
    "        data = data.append(feature_vector, ignore_index=True)\n",
    "        \n",
    "        counter += 1\n",
    "        if counter % n_iters_to_write == 0:\n",
    "            print(\"Counter: \" + str(counter) + \"... writing to outfile.\")\n",
    "            with open(outfile, \"a\") as f:\n",
    "                data.to_csv(f, header=False, index=False)\n",
    "            data = pd.DataFrame()\n",
    "    \n",
    "    # don't forget, the last few groups might not have been written out\n",
    "    if not df.empty:\n",
    "        with open(outfile, \"a\") as f:\n",
    "            data.to_csv(f, header=False, index=False)\n",
    "            data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 100... writing to outfile.\n",
      "Counter: 200... writing to outfile.\n",
      "Counter: 300... writing to outfile.\n",
      "Counter: 400... writing to outfile.\n",
      "Counter: 500... writing to outfile.\n",
      "Counter: 600... writing to outfile.\n",
      "Counter: 700... writing to outfile.\n",
      "Counter: 800... writing to outfile.\n",
      "Counter: 900... writing to outfile.\n",
      "Counter: 1000... writing to outfile.\n",
      "Counter: 1100... writing to outfile.\n",
      "Counter: 1200... writing to outfile.\n",
      "Counter: 1300... writing to outfile.\n",
      "Counter: 1400... writing to outfile.\n",
      "Counter: 1500... writing to outfile.\n",
      "Counter: 1600... writing to outfile.\n",
      "Counter: 1700... writing to outfile.\n",
      "19.625867999999997\n"
     ]
    }
   ],
   "source": [
    "tick = time.clock()\n",
    "train_fe = process_data(train.iloc[:10512], n_iters_to_write=100)\n",
    "tock = time.clock()\n",
    "print(tock - tick)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check that we've written out the data correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.read_csv(\"data/train_fe_flat.csv\", header=None, index_col=None)\n",
    "check.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
